# Resources on Statistical Learning, Kernel Methods, Support Vector Machines, Boltzman Machines, and KANs

## books

[The Elements of Statistical Learning; Data Mining, Inference, Prediction, Trevor Hastie, Robert Tibshirani, Jerome Friedman, Second Edition, 2017](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/EelementsOfStatisticalLearning_print12.pdf)

[A Solution Manual and Notes for: The Elements of Statistical Learning by Jerome Friedman, Trevor Hastie, and Robert Tibshirani, John L. Weatherwax, David Epstein, 2021](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Weatherwax_Epstein_Hastie_Solution_Manual.pdf)

[An Introduction to Statistical Learning with Applications in R, Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani, Second Edition, 2021](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/ISLRv2_website.pdf)

repos with solutions for the book _"An Introduction to Statistical Learning with Applications in R"_: [here](https://github.com/danhalligan/ISLRv2-solutions) and [here](https://github.com/asadoughi/stat-learning/)

[Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond, Bernhard Schoelkopf, Alexander J. Smola, MIT, 2002](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/scholkopf2002learning_with_kernels.pdf)

[Kernel Methods for Pattern Analysis, John Shawe-Taylor, Nello Cristiannini, 2004](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/kernel-methods-for-pattern-analysis.pdf)

[Learning Kernel Classifiers: Theory and Applications, Ralf Herbrich, MIT, 2002](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Learning_kernel_classifiers_Herbrich_2002.pdf)

[Statistical Inference, George Casella, Roger L. Berger, 2002, 2nd edition](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Statistical_Inference_Casella-Berger_2002.pdf)

[Principles of Statistical Inference, D.R. Cox, Cambridge U., 2006](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/principlesofstatisticalinference_cox_2006.pdf)

[Learning Theory from First Principles, Francis Bach, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Learning_Theory_from_First_Principles_Bach_2024.pdf)

[An Introduction to Statistical Modeling, Howard M. Taylor, 3rd Edition, 1998](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/An_Introduction_to_Stochastic_Modeling_Taylor_3Ed_1998.pdf)

[Machine Learning, Tom D. Mitchell, 1997](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Machine_Learning_Tom_Mitchell_1997.pdf)

[Introduction to Machine Learning, Laurent Younes, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Introduction_to_Machine_Learning_Younes_2024.pdf)

[A First Course in Monte Carlo Methods, D. Sanz-Alonso and O. Al-Ghattas, U of Chicago, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/MonteCarlo/A_First_Course_in_Monte_Carlo_Methods_Sanz_Alonso_2024.pdf)

[The Cauchy–Schwartz Master Class An Introduction to the Art of Mathematical Inequalities, J. Michael Steele, University of Pennsylvania, 2004](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/An_Introduction_To_The_Art_of_Mathematical_Inequalities_Steele_2004.pdf)

[Probabilistic Artificial Intelligence, Andreas Krause, Jonas Hübotter, 2025](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Probabilistic_Artificial_Intelligence_Krause_Huebotter_2025.pdf)

[Foundations of Machine Learning, Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar, 2012](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Foundations_of_Machine_Learning_Mohri_2012.pdf)

[Patterns, Predictions, and Actions, Moritz Hardt and Benjamin Recht, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Patterns_Predictions_and_Actions_Hardt_2024.pdf)

[Gaussian Processes and Reproducing Kernels: Connections and Equivalences, Motonobu Kanagawa et al, 2025](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Gaussian_Processes_and_Reproducing_Kernels-Connections_and_Equivalences_Kanagawa_2025.pdf)

[The Fundamentals of Heavy Tails: Properties, Emergence, and Estimation, Jayakrishnan Nair, Adam Wierman, Bert Zwart, 2021, Draft](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/The_Fundamentals_of_Heavy_Tails_Properties_Emergence_Estimation_Nair_2021_Draft.pdf)

## lecture notes

[Lecture Notes on Linear Regression, Danillo Petti, U. of Essex, 2023-2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/lecture_notes/regression/Lecture_notes_in_Linear_Regression_Danilo_Petti_2023.pdf)

[Optimization for Machine Learning, Lecture Notes CS-439, Spring 2025, Bernd Gartner, ETH, Martin Jaggi, EPFL](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/lecture_notes/Optimization_for_Machine_Learning_Gaertner_Lecture_Notes_CS-439_Spring_2025.pdf)

## articles

### Classification and Regression Trees

[Data Mining with Decision Trees: Theory and Applications, 2nd Edition, Lior Rokach, Oded Maimon, 2014](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/classification_and_regression/DataMiningwithDecisionTrees_Theory_and_Applications_2nd_ed_Rokach_Maimon_2014.pdf)

[Decision Tree Learning, Chapter 3 of the book "Machine Learning" by Tom D. Mitchell, 1997](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/classification_and_regression/Decision_Tree_Learning_Chapter3_Tom_Mitchell.pdf)

[Classification Algorithms and Regression Trees, Chapter 11 of Nonlinear Estimation and Classification, Ingo Ruczinsky, 2003](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/classification_and_regression/Classification_Algorithms_and_Regression_Trees_Ingo_Ruszinsky.pdf)

[Incremental Induction of Decision Trees, Paul E. Utgoff, UMass-Amherst, 1989](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/classification_and_regression/Incremental_Induction_of_Decision_Trees_Utgoff_1989.pdf)

[Simplifying Decision Trees, JR Quinlan, MIT, 1987](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/classification_and_regression/Simplifying_Decision_Trees_JR_Quinlan_1987.pdf)

[A Framework for Sensitivity Analysis of Decision Trees, Bogumil Kaminski et al, 2017](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/classification_and_regression/A_framework_for_sensitivity_analysis_of_decision_trees_Kaminski_2017.pdf)

[The Mathematical Equivalence between Decision Trees and Artificial Neural Networks, Miquel Noguer i Alonso, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/decision_trees/Mathemaical_Equivalence_between_DecisionTrees_and_ANN_Allonco_2024.pdf)

[BART - Bayesian Additive Regression Trees, Hugh Chipman et al, 2010](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/regression_trees/BART_Bayesian_Additive_Regression_Trees_Hugh_2010.pdf)

### Gradient Boosting

[Greedy Function Approximation: A Gradient Boosting Machine, JH Friedman, 2001](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/classification_and_regression/Greedy_Function_Approximation_A_Gradient_Boosting_Machine_Friedman_2001.pdf)


### Bagging Predictors

[Bagging Predictors, Leo Breiman, Technical Report N 421, 1994](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/classification_and_regression/baggingBreiman.pdf)

### Random Forests

[Random Forests, Leo Breiman, UC Berkeley, 2001](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/classification_and_regression/randomforest2001.pdf)

### Generalization in Machine Learning

[Modeling Generalization in Machine Learning - A Methodological and Computational Study, Pietro Barbiero et al, Cambridge University, 2020](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/generalization/Modeling_Generalization_in_Machine_Learning-A_Methodoligical_and_Computational_Study_Barbiero_2020.pdf)

### Statistical Learning and Inference

[Boosting any learning algorithm with Statistically Enhanced Learning, Florian Felice et al, 2025](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/Boosting_any_learning_algorithm_with_Statistically_Enhanced_Learning_Felice_2025.pdf)

[Likelihood Inference, Nancy Reid, U of Toronto, 2010](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/statistical_inference/Likelihood_inference_Reid_UToronto_2010.pdf)


### Inductive Bias in Learning Models

[Hints, Yaser-Abu Mostafa, 1995](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/inductive_bias/Hints_Abu-Yaser_Moustafa_1995.pdf)

[The Lack of Apriori Distinctions Between Learning Algorithms, David H. Wolpert, 1996](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/inductive_bias/the-lack-of-a-priori-distinctions-between-learning-Wolpert-1996.pdf)

[The Role of Occam's Razor in Knowledge Discovery, Pedro Domingos, 1999](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/inductive_bias/The_Role_of_Occam_Razor_in_Knowledge_Discovery_Domingos_1999.pdf)

[Ockham’s Razor, Truth, and Information, Kevin T. Kelly, CMU, 2008](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/inductive_bias/Ockham_Razor_Truth_and_Information_Kelly_2008.pdf)


### Kernel Methods, Support Vector Machines

[Kernel Methods in Machine Learning, Thomas Hoffman, Bernhard Schoelkopf, Alexander J. Smolla, 2008](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/Kernel_methods_in_Machine_Learning_Hoffman_Scholkopf_Smolla_2008.pdf)

[Gentle Introduction to the Kernel Distance, JR Phillips et al, 2011](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/A_Gentle_Introduction_to_the_Kernel_Distance_Phillips_2011.pdf)

[A Tutorial on Support Vector Machines for Pattern Recongition, Christopher Burgess, 1998](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/svm/svmtutorial_Burgess_1998.pdf)

[The Kernel Trick for Distances, B. Schoelkopf, Microsoft Research, NIPS 2000](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/NIPS-2000-the-kernel-trick-for-distances-Schoelkopf.pdf)

[On The Optimality of Kernels for High-Dimensional Clustering, LC Vankadara et al, 2019](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/On_the_Optimality_of_Kernels_for_High-Dimensional_Clustering_Vankadara_2019.pdf)

[Kernel Methods on Riemannian Manifolds with Gaussian RBF Kernels, S. Jayasumana et al, 2015](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/Kernel_Methods_on_Riemannian_Manifolds_with_Gaussian_RBF_Kernels_Jayasumana_2015.pdf)

[An Innovative Support Vector Machine Based Method for Contextual Image Classification, RG Negri et al, 2013](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/svm/An_innovative_support_vector_machine_based_method_for_Contextual_image_classification_Negri_2013.pdf)

[Kernel methods for high dimensional data analysis, Alba Chiara de Vitis, 2020](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/Kernel_methods_for_high_dimensional_data_analysis_de_Vitis_2020.pdf)

[Every Model Learned by Gradient Descent Is Approximately a Kernel Machine, Pedro Domingos, 2020](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/Every_Model_Learned_by_Gradient_Descent_Is_Approximately_a_Kernel_Machine_Domingos_2020.pdf)

[Transformers as Support Vector Machines, Davoud Ataee Tarzanagh et al, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/svm/Transformers_as_Support_Vector_Machines_Tarzanagh_225.pdf)

### Kolmogorov Superposition Theorem

[The Kolmogorov Superposition Theorem, Torbjörn Hedberg, 1971](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/Kolmogorov_superposition_theorem/Kolmogorov_superposition_theorem_proof_Hedberg_1971.pdf)

[On a constructive proof of Kolmogorov’s superposition theorem, Juergen Braun et al, 2009](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/Kolmogorov_superposition_theorem/On_a_constructive_proof_of_Kolmogorov_superposition_theorem_Braun_2009.pdf)

[On the Structure of Continuous Functions of Several Variables, D. Sprecher, 1965](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/Kolmogorov_superposition_theorem/On_the_Structure_of_Continuous_Functions_of_Several_Variables_Sprecher_1965.pdf)

[Dimension of metric spaces and Hilbert's problem 13, PA Ostrand, 1965](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/Kolmogorov_superposition_theorem/Dimension_of_metric_spaces_and_Hilberts_problem_13_Ostrand_1965.pdf)

[On the representation by linear superpositions, V. Ismailov, 2008](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/Kolmogorov_superposition_theorem/On_the_representation_by_linear_superpositions_Vugar_2008.pdf)

### Learning as an Approximation, The Double Descent Phenomenon

[A Brief Prehistory of Double Descent, Marco Loog et al, 2020](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/learning_as_approximation/A_Brief_Prehistory_of_Double_Descent_Loog_2020.pdf)

[Theory of the Double Descent Phenomena in High-Dimensional Linear Regression, Charles H. Mafrtin, 2025](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/learning_as_approximation/Theory_of_the_Double_Descent_Phenomena_in_High-Dimensional_Linear_Regression_Martin_2025.pdf)

[Reconciling modern machine learning practice and the bias-variance trade-off, Mikhail Belkin et al, 2019](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/learning_as_approximation/Reconciling_modern_machine_learning_practice_and_the_bias-variance_trade-off_Belkin_2019.pdf)

[Statistical Mechanics of Learning, Andreas Engel, 1999](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/learning_as_approximation/Statistical_Mechanics_of_Learning_Engel_1999.pdf)

[The Statistical Mechanics of Learning A Rule, T. Watkin et al, 1993](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/learning_as_approximation/The_Statistical_Mechanics_of_Learning_A_Rule_1993RevModPhysWatkin.pdf)

[A Theory of Networks for Approximation and Learning, T. Poggio et al, 1989](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/learning_as_approximation/A_Theory_of_Networks_for_Approximation_and_Learning_Poggio_Girosi_1989.pdf)

[The Peaking Phenomenon in Semi-Supervised Learning, JH Krijte, M. Loog, 2016](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/learning_as_approximation/The_Peaking_Phenomenon_in_Semi-supervised_Learning_Krijthe_2016.pdf)

### Kolmogorov-Arnold Networks
[KAN: Kolmogorov-Arnold Networks, Z. Liu et al, MIT, Caltech, NEU, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/KAN-Kolmogorov%E2%80%93Arnold_Networks_Liu_2024.pdf)

[KAN 2.0: Kolmogorov-Arnold Networks Meet Science, Z. Liu et al, MIT, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/KAN_2.0-Kolmogorov-Arnold_Networks_Meet_Science_Liu_2024.pdf)

[Kolmogorov-Arnold Representation Theorem, Wikipedia](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold_representation_theorem)

[Representing continuous functions of several variables as a superposition of single variable continuous functions and addition, A.N. Kolmogorov, Dokl. Akad. Nauk SSSR, 1957](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Representing_continuous_functions_of_several_variables_as_a_superposition_of_single_variate_continuous_functions_and_addition_Kolmogorov_1957.pdf)

[On Functions of Three Variables, V.I. Arnold, 1957](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_Functions_of_Three_Vairables_Arnold57.pdf)

[On The Structure of Continuous Functions of Several Variables, David A. Spercher, 1965](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_the_structure_of_continuous_functions_of_several_variables_Spercher_1965.pdf)

[On The Approximate Realization of Continuous Functions by Neural Networks, Ken-ichi Funahashi, 1989](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_the_Approximate_Realization_of_Continuous_Mappings_by_Neural_Networks_Funahashi_1989.pdf)

[Rates of Convergence of Estimates, Kolmogorov's Entropy, and the Dimensionality Reduction Principle in Regression, T. Nicoleris et al, Universite de Montreal, 1998](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Rates_of_Convergence_of_Estimates_Kolmogorov_Entropy_and_the_Dimensionality_Reduction_Principle_in_Regression_Nicoleris_1997.pdf)

[On a constructive proof of Kolmogorov's supperposition theorem, Juergen Braun, Michael Griebel, 2009](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_a_constructive_proof_of_Kolmogorov_superposition_theorem_Braun_2009.pdf)

[Kolmogorov's Supperposition Theorem and its Applications, Liu, Imperial College, Xing Liu, PhD Thesis, 2015](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Kolmogorov_Superposition_Theorem_and_Its_Applications_Liu_ImperialCollege_PhD_thesis_2015.pdf)

[Hilbert 13: Are There Any Genuine Continuous Multivariate Real Valued Functions? Sidney A. Morris, 2020](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Hilbert_13-Are_There_Any_Genuine_Continuous_Multivariate_Real-Valued_Functions_Morris_2020%3F.pdf)

[On The Kolmogorov Neural Networks, A. Ismailova et al, 2023](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_the_Kolmogorov_neural_networks_Ismaiylova_2023.pdf)

[Kolmogorov-Arnold Networks for Time-Series Analysis, Chrisitian J. Vaca-Rubio et al, CTTC, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Kolmogorov-Arnold_Networks_for_Time_Series_Analysis_Vaca-Rubio_2024.pdf)

[Wav-KAN: Wavelet Kolmogorov-Arnold Networks, Z. Bozorgasi et al, IEEE, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Wav-KAN-Wavelet_Kolmogorov-Arnold_Networks_Bozorgasi_2024.pdf)

[Kolmogorov Arnold Graph Neural Networks Gianluca De Carlo et al, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Kolmogorov_Arnold_Graph_Neural_Networks_De_Carlo_2024.pdf)

[KAN: Why and How Does It Work? A Deep Dive, Saptashwa Bhattacharyya, Medium, 2024](https://towardsdatascience.com/kan-why-and-how-does-it-work-a-deep-dive-1adab4837fa3)

[Kolmogorov–Arnold Networks Are About To Change The AI World Forever, Manushi Mukhi, 2024](https://medium.com/accredian/kolmogorov-arnold-networks-kan-are-about-to-change-the-ai-world-forever-687f6d0b4d93)

[Implementing a Kolmogorov-Arnold Network with PyTorch, Robert McMenemy, Medium, 2024](https://rabmcmenemy.medium.com/implementing-a-kolmogorov-arnold-network-with-pytorch-5409ce803fab)

[Kolmogorov-Arnold Networks (KANs) Are Being Used To Boost Graph Deep Learning Like Never Before, Dr. Ashish Bamania, Medium, 2024](https://levelup.gitconnected.com/kolmogorov-arnold-networks-kans-are-being-used-to-boost-graph-deep-learning-like-never-before-2d39fec7dfc3)

[Prediction via Shapley Value Regression, Amr Alkhatib et al, 2025](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Prediction_via_Shapley_Value_Regression_Alkhatib_2025.pdf)

### Generalized Additive Models

[Generalized Additive Models, T. Hastie, R. Tibshirani, 1986](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/additive_models/Generalized_Additive_Models_Hastie_1986.pdf)

[Estimation of Generalized Additive Models, Prabir Burman, 1990](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/additive_models/Estimation_of_generalized_additive_models_Burman_1990.pdf)

[Additive Decision Trees, W. Brett Kennedy, May 2024, Towards Data Science](https://towardsdatascience.com/additive-decision-trees-85f2feda2223)

related githib repo: https://github.com/Brett-Kennedy/AdditiveDecisionTree

[Generalized Monotone Additive Latent Variable Models, Sylvain Sardy et al, U. of Geneva, 2010](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/additive_models/Generalized_monotone_additive_latent_variable_models_Sardy_2010.pdf)

### Principal Component Analysis

[A Geometric Analysis of PCA, Ayoub El Hanchi et al, U of Toronto, 2025](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/PCA/A_Geometric_Analysis_of_PCA_El_Hanchi_2025.pdf)

### kNN

[Interpretable kNN (ikNN), W Brett Kennedy, May 2024](https://towardsdatascience.com/interpretable-knn-iknn-33d38402b8fc)

related github repo: https://github.com/Brett-Kennedy/ikNN 

### The Lanczos Algorithm

[The Lanczos algorithm for matrix functions: a handbook for scientists, Tyler Chen, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/Lanczos_algorithm/The_Lanczos_algorithm_for_matrix_functions_Chen_2024.pdf)

### Non-linear models

[Non-Linearity: Can Linear Regression Compete With Gradient Boosting? Samuele Mazzanti, 2024](https://towardsdatascience.com/non-linearity-can-linear-regression-compete-with-gradient-boosting-e4f88d81d105)

### ML in hyperbolic space

[A Group-Theoretic Framework for Machine Learning in Hyperbolic Spaces, Vladimir Jacimovic, 2025](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/hyperbolic_spaces/A_Group-Theoretic_Framework_for_Machine_Learning_in_Hyperbolic_Spaces_2025.pdf)

## conferences

[Machine Learning, Optimization, and Data Science, 5th International Conference, LOD 2019 Siena, Italy, September 10–13, 2019 Proceedings](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Machine_Learning_Optimization_and_Data_Science_5_conference_LOD_2019.pdf)

## Videos

### Pascal Poupart CS480/680 Statisitical Learning 2019

[Lecture 1: Intro to ML/Statistical Learning](https://youtu.be/GouhgbE5gPk?si=SrsVl2XbILvgOUbn)

[Lecture 2: K-nearest neighbors](https://youtu.be/5AXF14_OCNE?si=YQwXYNxenVHeCHIN)

[Lecture 3: Linear Regression](https://youtu.be/z9SUst3X5iU?si=PNis1zap53dMlQWu)

[Lecture 4: Statistical Learning](https://youtu.be/hSZGE_CJnGg?si=vfJzFIf1rjg7fDxD)

[Lecture 5: Statistical Linear Regression](https://youtu.be/bvh_HObXZmQ?si=6PRIXhqdj6THFZ5s)

[Lecture 6: Tools for Survey](https://youtu.be/5rk4wWKvd6c?si=hd2Eaaz4oTKZbSLJ)

[Lecture 6: Kaggle datasets and competitions](https://youtu.be/WoLTLru_UBI?si=-XxcSrH4K24z7c7Z)

[lecture 6: Normalizing flows](https://youtu.be/3nmBnudFAR8?si=WK3dnK_HWQ-lw-jN)

[Lecture 6: Unsupervised word translation](https://youtu.be/8XZolToe1jM?si=4r86auz4v5GZvuWX)

[Lecture 6: Fact checking and Reinforcement Learning](https://youtu.be/bmczQuXw7ak?si=tC0Pa7p7gq6u810f)

[Lecture 6: Sum-product Networks](https://youtu.be/IaLGMJzCdIw?si=VIRICxcWsFYwwc6n)

[Lecture 6: EM and Mixture Models](https://youtu.be/jeo7Cpsyttc?si=s6Me7b28_KW9LgZA)

[Lecture 6: Model Compression for NLP](https://youtu.be/tRNgLb0S2mo?si=4hfq0s2wQXcxVYNb)

[Lecture 7: Mixture of Gaussians](https://youtu.be/Weq0KiSTHAs?si=5oussc7yiF1TLm8-)

[Lecture 8: Logistic Regression and Generalized Linear Models](https://youtu.be/CXV-vVoPFHw?si=jlb17xTE28b6UNAt)

[Lecture 9: Perceptrons and single layer networks](https://youtu.be/dXxuCARJ1CY?si=OhM42cZuJN8VMtaF)

[Lecture 10: Multi-layer neural networks and backpropagation](https://youtu.be/-SCDyTz0mWI?si=N4XK6JxpSSp1fFRk)

[Lecture 11: Kernel methods](https://youtu.be/nzSBvINmg28?si=5buft116QODQn-O7)

[Lecture 12: Gaussian Processes](https://youtu.be/exqpaqaPG2M?si=eLB9k2XAg8oLIjAv)

[Lecture 13: Support Vector Machines](https://youtu.be/pM14uopquiA?si=nbccMKaMX8nMdGcK)

[Lecture 14: Support Vector Machines (continued)](https://youtu.be/-9aO4sM_zHg?si=GSsAidj2q52-iBXo)

[Lecture 15: Deep Learning Networks](https://youtu.be/j-O9Fu45zdU?si=WOLbkseYLY4QEMtD)

[Lecture 16: Convolutional Neural Networks](https://youtu.be/F08TkdjdrL8?si=evwoROZCFmWMOGxu)

[Lecture 17: Hidden Markov Models](https://youtu.be/9EHWTHJkqUY?si=jqMLBrJKBs_kHK75)

[Lecture 18: Recurrent and Recursive Networks](https://youtu.be/lClNhXVNZ-0?si=7vxiDtbq5dgrUiwu)

[Lecture 19: Attention and Transformer Networks](https://youtu.be/OyFJWRnt_AY?si=lVMMTojOkT1G2JEN)

[Lecture 20: Autoencoders](https://www.youtube.com/watch?v=E28CVTbNoSA)

[Lecture 21: Generative networks (variational autoencoders and GANs)](https://youtu.be/DWVlEw0D3gA?si=wSb0Edy9LvrCKCS0)

[Lecture 22: Ensemble Learning (Bagging and Boosting)](https://youtu.be/gTUigPt8fVo?si=V97gcOfWRr7_-NqH)

[Lecture 23: Normalizing Flows](https://youtu.be/3KUvxIOJD0k?si=WIENaPzAroiNEVUv)

[Lecture 24: Gradient boosting, bagging, decision forests](https://youtu.be/B3sN1BymGdc?si=AusLuuM9aT3EL5lf)
