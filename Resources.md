# Resources on Statistical Learning, Kernel Methods, Support Vector Machines, Boltzman Machines, and KANs

## books

[The Elements of Statistical Learning; Data Mining, Inference, Prediction, Trevor Hastie, Robert Tibshirani, Jerome Friedman, Second Edition, 2017](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/EelementsOfStatisticalLearning_print12.pdf)

[A Solution Manual and Notes for: The Elements of Statistical Learning by Jerome Friedman, Trevor Hastie, and Robert Tibshirani, John L. Weatherwax, David Epstein, 2021](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Weatherwax_Epstein_Hastie_Solution_Manual.pdf)

[An Introduction to Statistical Learning with Applications in R, Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani, Second Edition, 2021](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/ISLRv2_website.pdf)

repos with solutions for the book _"An Introduction to Statistical Learning with Applications in R"_: [here](https://github.com/danhalligan/ISLRv2-solutions) and [here](https://github.com/asadoughi/stat-learning/)

[Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond, Bernhard Schoelkopf, Alexander J. Smola, MIT, 2002](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/scholkopf2002learning_with_kernels.pdf)

[Kernel Methods for Pattern Analysis, John Shawe-Taylor, Nello Cristiannini, 2004](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/kernel-methods-for-pattern-analysis.pdf)

[Learning Kernel Classifiers: Theory and Applications, Ralf Herbrich, MIT, 2002](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Learning_kernel_classifiers_Herbrich_2002.pdf)

[Statistical Inference, George Casella, Roger L. Berger, 2002, 2nd edition](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Statistical_Inference_Casella-Berger_2002.pdf)

[Principles of Statistical Inference, D.R. Cox, Cambridge U., 2006](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/principlesofstatisticalinference_cox_2006.pdf)

[Learning Theory from First Principles, Francis Bach, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Learning_Theory_from_First_Principles_Bach_2024.pdf)

[An Introduction to Statistical Modeling, Howard M. Taylor, 3rd Edition, 1998](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/An_Introduction_to_Stochastic_Modeling_Taylor_3Ed_1998.pdf)

[A First Course in Monte Carlo Methods, D. Sanz-Alonso and O. Al-Ghattas, U of Chicago, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/MonteCarlo/A_First_Course_in_Monte_Carlo_Methods_Sanz_Alonso_2024.pdf)

## articles

### Decision Trees

[The Mathematical Equivalence between Decision Trees and Artificial Neural Networks, Miquel Noguer i Alonso, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/decision_trees/Mathemaical_Equivalence_between_DecisionTrees_and_ANN_Allonco_2024.pdf)

### Statistical inference

[Likelihood Inference, Nancy Reid, U of Toronto, 2010](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/statistical_inference/Likelihood_inference_Reid_UToronto_2010.pdf)

### Kernel Methods, Support Vector Machines

[Kernel Methods in Machine Learning, Thomas Hoffman, Bernhard Schoelkopf, Alexander J. Smolla, 2008](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/Kernel_methods_in_Machine_Learning_Hoffman_Scholkopf_Smolla_2008.pdf)

[Gentle Introduction to the Kernel Distance, JR Phillips et al, 2011](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/A_Gentle_Introduction_to_the_Kernel_Distance_Phillips_2011.pdf)

[A Tutorial on Support Vector Machines for Pattern Recongition, Christopher Burgess, 1998](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/svm/svmtutorial_Burgess_1998.pdf)

[The Kernel Trick for Distances, B. Schoelkopf, Microsoft Research, NIPS 2000](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/NIPS-2000-the-kernel-trick-for-distances-Schoelkopf.pdf)

[On The Optimality of Kernels for High-Dimensional Clustering, LC Vankadara et al, 2019](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/On_the_Optimality_of_Kernels_for_High-Dimensional_Clustering_Vankadara_2019.pdf)

[Kernel Methods on Riemannian Manifolds with Gaussian RBF Kernels, S. Jayasumana et al, 2015](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/Kernel_Methods_on_Riemannian_Manifolds_with_Gaussian_RBF_Kernels_Jayasumana_2015.pdf)

[An Innovative Support Vector Machine Based Method for Contextual Image Classification, RG Negri et al, 2013](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/svm/An_innovative_support_vector_machine_based_method_for_Contextual_image_classification_Negri_2013.pdf)

[Kernel methods for high dimensional data analysis, Alba Chiara de Vitis, 2020](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/kernel_methods/Kernel_methods_for_high_dimensional_data_analysis_de_Vitis_2020.pdf)

### Kolmogorov-Arnold Networks
[KAN: Kolmogorov-Arnold Networks, Z. Liu et al, MIT, Caltech, NEU, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/KAN-Kolmogorov%E2%80%93Arnold_Networks_Liu_2024.pdf)

[KAN 2.0: Kolmogorov-Arnold Networks Meet Science, Z. Liu et al, MIT, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/KAN_2.0-Kolmogorov-Arnold_Networks_Meet_Science_Liu_2024.pdf)

[Kolmogorov-Arnold Representation Theorem, Wikipedia](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold_representation_theorem)

[Representing continuous functions of several variables as a superposition of single variable continuous functions and addition, A.N. Kolmogorov, Dokl. Akad. Nauk SSSR, 1957](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Representing_continuous_functions_of_several_variables_as_a_superposition_of_single_variate_continuous_functions_and_addition_Kolmogorov_1957.pdf)

[On Functions of Three Variables, V.I. Arnold, 1957](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_Functions_of_Three_Vairables_Arnold57.pdf)

[On The Structure of Continuous Functions of Several Variables, David A. Spercher, 1965](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_the_structure_of_continuous_functions_of_several_variables_Spercher_1965.pdf)

[On The Approximate Realization of Continuous Functions by Neural Networks, Ken-ichi Funahashi, 1989](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_the_Approximate_Realization_of_Continuous_Mappings_by_Neural_Networks_Funahashi_1989.pdf)

[Rates of Convergence of Estimates, Kolmogorov's Entropy, and the Dimensionality Reduction Principle in Regression, T. Nicoleris et al, Universite de Montreal, 1998](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Rates_of_Convergence_of_Estimates_Kolmogorov_Entropy_and_the_Dimensionality_Reduction_Principle_in_Regression_Nicoleris_1997.pdf)

[On a constructive proof of Kolmogorov's supperposition theorem, Juergen Braun, Michael Griebel, 2009](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_a_constructive_proof_of_Kolmogorov_superposition_theorem_Braun_2009.pdf)

[Kolmogorov's Supperposition Theorem and its Applications, Liu, Imperial College, Xing Liu, PhD Thesis, 2015](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Kolmogorov_Superposition_Theorem_and_Its_Applications_Liu_ImperialCollege_PhD_thesis_2015.pdf)

[Hilbert 13: Are There Any Genuine Continuous Multivariate Real Valued Functions? Sidney A. Morris, 2020](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Hilbert_13-Are_There_Any_Genuine_Continuous_Multivariate_Real-Valued_Functions_Morris_2020%3F.pdf)

[On The Kolmogorov Neural Networks, A. Ismailova et al, 2023](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/On_the_Kolmogorov_neural_networks_Ismaiylova_2023.pdf)

[Kolmogorov-Arnold Networks for Time-Series Analysis, Chrisitian J. Vaca-Rubio et al, CTTC, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Kolmogorov-Arnold_Networks_for_Time_Series_Analysis_Vaca-Rubio_2024.pdf)

[Wav-KAN: Wavelet Kolmogorov-Arnold Networks, Z. Bozorgasi et al, IEEE, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Wav-KAN-Wavelet_Kolmogorov-Arnold_Networks_Bozorgasi_2024.pdf)

[Kolmogorov Arnold Graph Neural Networks Gianluca De Carlo et al, 2024](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/KAN/Kolmogorov_Arnold_Graph_Neural_Networks_De_Carlo_2024.pdf)

[KAN: Why and How Does It Work? A Deep Dive, Saptashwa Bhattacharyya, Medium, 2024](https://towardsdatascience.com/kan-why-and-how-does-it-work-a-deep-dive-1adab4837fa3)

[Kolmogorov–Arnold Networks Are About To Change The AI World Forever, Manushi Mukhi, 2024](https://medium.com/accredian/kolmogorov-arnold-networks-kan-are-about-to-change-the-ai-world-forever-687f6d0b4d93)

[Implementing a Kolmogorov-Arnold Network with PyTorch, Robert McMenemy, Medium, 2024](https://rabmcmenemy.medium.com/implementing-a-kolmogorov-arnold-network-with-pytorch-5409ce803fab)

[Kolmogorov-Arnold Networks (KANs) Are Being Used To Boost Graph Deep Learning Like Never Before, Dr. Ashish Bamania, Medium, 2024](https://levelup.gitconnected.com/kolmogorov-arnold-networks-kans-are-being-used-to-boost-graph-deep-learning-like-never-before-2d39fec7dfc3)

### Generalized Additive Models

[Generalized Additive Models, T. Hastie, R. Tibshirani, 1986](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/additive_models/Generalized_Additive_Models_Hastie_1986.pdf)

[Estimation of Generalized Additive Models, Prabir Burman, 1990](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/additive_models/Estimation_of_generalized_additive_models_Burman_1990.pdf)

[Additive Decision Trees, W. Brett Kennedy, May 2024, Towards Data Science](https://towardsdatascience.com/additive-decision-trees-85f2feda2223)

related githib repo: https://github.com/Brett-Kennedy/AdditiveDecisionTree

[Generalized Monotone Additive Latent Variable Models, Sylvain Sardy et al, U. of Geneva, 2010](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/additive_models/Generalized_monotone_additive_latent_variable_models_Sardy_2010.pdf)

### kNN

[Interpretable kNN (ikNN), W Brett Kennedy, May 2024](https://towardsdatascience.com/interpretable-knn-iknn-33d38402b8fc)

related github repo: https://github.com/Brett-Kennedy/ikNN 

### Non-linear models

[Non-Linearity: Can Linear Regression Compete With Gradient Boosting? Samuele Mazzanti, 2024](https://towardsdatascience.com/non-linearity-can-linear-regression-compete-with-gradient-boosting-e4f88d81d105)

### ML in hyperbolic space

[A Group-Theoretic Framework for Machine Learning in Hyperbolic Spaces, Vladimir Jacimovic, 2025](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/articles/hyperbolic_spaces/A_Group-Theoretic_Framework_for_Machine_Learning_in_Hyperbolic_Spaces_2025.pdf)

## conferences

[Machine Learning, Optimization, and Data Science, 5th International Conference, LOD 2019 Siena, Italy, September 10–13, 2019 Proceedings](https://github.com/dimitarpg13/statistical_learning_and_kernel_methods/blob/main/literature/books/Machine_Learning_Optimization_and_Data_Science_5_conference_LOD_2019.pdf)

## Videos

### Pascal Poupart CS480/680 Statisitical Learning 2019

[Lecture 1: Intro to ML/Statistical Learning](https://youtu.be/GouhgbE5gPk?si=SrsVl2XbILvgOUbn)

[Lecture 2: K-nearest neighbors](https://youtu.be/5AXF14_OCNE?si=YQwXYNxenVHeCHIN)

[Lecture 3: Linear Regression](https://youtu.be/z9SUst3X5iU?si=PNis1zap53dMlQWu)

[Lecture 4: Statistical Learning](https://youtu.be/hSZGE_CJnGg?si=vfJzFIf1rjg7fDxD)

[Lecture 5: Statistical Linear Regression](https://youtu.be/bvh_HObXZmQ?si=6PRIXhqdj6THFZ5s)

[Lecture 6: Tools for Survey](https://youtu.be/5rk4wWKvd6c?si=hd2Eaaz4oTKZbSLJ)

[Lecture 6: Kaggle datasets and competitions](https://youtu.be/WoLTLru_UBI?si=-XxcSrH4K24z7c7Z)

[lecture 6: Normalizing flows](https://youtu.be/3nmBnudFAR8?si=WK3dnK_HWQ-lw-jN)

[Lecture 6: Unsupervised word translation](https://youtu.be/8XZolToe1jM?si=4r86auz4v5GZvuWX)

[Lecture 6: Fact checking and Reinforcement Learning](https://youtu.be/bmczQuXw7ak?si=tC0Pa7p7gq6u810f)

[Lecture 6: Sum-product Networks](https://youtu.be/IaLGMJzCdIw?si=VIRICxcWsFYwwc6n)

[Lecture 6: EM and Mixture Models](https://youtu.be/jeo7Cpsyttc?si=s6Me7b28_KW9LgZA)

[Lecture 6: Model Compression for NLP](https://youtu.be/tRNgLb0S2mo?si=4hfq0s2wQXcxVYNb)

[Lecture 7: Mixture of Gaussians](https://youtu.be/Weq0KiSTHAs?si=5oussc7yiF1TLm8-)

[Lecture 8: Logistic Regression and Generalized Linear Models](https://youtu.be/CXV-vVoPFHw?si=jlb17xTE28b6UNAt)

[Lecture 9: Perceptrons and single layer networks](https://youtu.be/dXxuCARJ1CY?si=OhM42cZuJN8VMtaF)

[Lecture 10: Multi-layer neural networks and backpropagation](https://youtu.be/-SCDyTz0mWI?si=N4XK6JxpSSp1fFRk)

[Lecture 11: Kernel methods](https://youtu.be/nzSBvINmg28?si=5buft116QODQn-O7)

[Lecture 12: Gaussian Processes](https://youtu.be/exqpaqaPG2M?si=eLB9k2XAg8oLIjAv)

[Lecture 13: Support Vector Machines](https://youtu.be/pM14uopquiA?si=nbccMKaMX8nMdGcK)

[Lecture 14: Support Vector Machines (continued)](https://youtu.be/-9aO4sM_zHg?si=GSsAidj2q52-iBXo)

[Lecture 15: Deep Learning Networks](https://youtu.be/j-O9Fu45zdU?si=WOLbkseYLY4QEMtD)

[Lecture 16: Convolutional Neural Networks](https://youtu.be/F08TkdjdrL8?si=evwoROZCFmWMOGxu)

[Lecture 17: Hidden Markov Models](https://youtu.be/9EHWTHJkqUY?si=jqMLBrJKBs_kHK75)

[Lecture 18: Recurrent and Recursive Networks](https://youtu.be/lClNhXVNZ-0?si=7vxiDtbq5dgrUiwu)

[Lecture 19: Attention and Transformer Networks](https://youtu.be/OyFJWRnt_AY?si=lVMMTojOkT1G2JEN)

[Lecture 20: Autoencoders](https://www.youtube.com/watch?v=E28CVTbNoSA)

[Lecture 21: Generative networks (variational autoencoders and GANs)](https://youtu.be/DWVlEw0D3gA?si=wSb0Edy9LvrCKCS0)

[Lecture 22: Ensemble Learning (Bagging and Boosting)](https://youtu.be/gTUigPt8fVo?si=V97gcOfWRr7_-NqH)

[Lecture 23: Normalizing Flows](https://youtu.be/3KUvxIOJD0k?si=WIENaPzAroiNEVUv)

[Lecture 24: Gradient boosting, bagging, decision forests](https://youtu.be/B3sN1BymGdc?si=AusLuuM9aT3EL5lf)
